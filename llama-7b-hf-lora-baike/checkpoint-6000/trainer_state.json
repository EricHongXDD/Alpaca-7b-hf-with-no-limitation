{
  "best_metric": 1.6820251941680908,
  "best_model_checkpoint": "/root/Shelter/llama-7b-hf-lora-baike/checkpoint-6000",
  "epoch": 2.6234561154224503,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 2.2091,
      "step": 20
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00011999999999999999,
      "loss": 1.8942,
      "step": 40
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00017999999999999998,
      "loss": 1.7962,
      "step": 60
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00023999999999999998,
      "loss": 1.7057,
      "step": 80
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0003,
      "loss": 1.7003,
      "step": 100
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00029911255731400677,
      "loss": 1.7214,
      "step": 120
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00029822511462801357,
      "loss": 1.7488,
      "step": 140
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00029733767194202037,
      "loss": 1.6901,
      "step": 160
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0002964502292560272,
      "loss": 1.69,
      "step": 180
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00029556278657003396,
      "loss": 1.7189,
      "step": 200
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002946753438840408,
      "loss": 1.7115,
      "step": 220
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002937879011980476,
      "loss": 1.6678,
      "step": 240
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0002929004585120544,
      "loss": 1.7029,
      "step": 260
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0002920130158260612,
      "loss": 1.6668,
      "step": 280
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.000291125573140068,
      "loss": 1.6505,
      "step": 300
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0002902381304540748,
      "loss": 1.6628,
      "step": 320
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00028935068776808165,
      "loss": 1.7026,
      "step": 340
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00028846324508208845,
      "loss": 1.6182,
      "step": 360
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0002875758023960952,
      "loss": 1.6784,
      "step": 380
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00028668835971010204,
      "loss": 1.6306,
      "step": 400
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00028580091702410884,
      "loss": 1.6745,
      "step": 420
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00028491347433811563,
      "loss": 1.6467,
      "step": 440
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00028402603165212243,
      "loss": 1.6769,
      "step": 460
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00028313858896612923,
      "loss": 1.662,
      "step": 480
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000282251146280136,
      "loss": 1.6586,
      "step": 500
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0002813637035941429,
      "loss": 1.6864,
      "step": 520
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0002804762609081497,
      "loss": 1.6742,
      "step": 540
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00027958881822215647,
      "loss": 1.6234,
      "step": 560
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00027870137553616327,
      "loss": 1.6427,
      "step": 580
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00027781393285017007,
      "loss": 1.6534,
      "step": 600
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00027692649016417686,
      "loss": 1.6488,
      "step": 620
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00027603904747818366,
      "loss": 1.6318,
      "step": 640
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00027515160479219046,
      "loss": 1.6505,
      "step": 660
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00027426416210619726,
      "loss": 1.6115,
      "step": 680
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0002733767194202041,
      "loss": 1.6472,
      "step": 700
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0002724892767342109,
      "loss": 1.6277,
      "step": 720
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0002716018340482177,
      "loss": 1.6444,
      "step": 740
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0002707143913622245,
      "loss": 1.6128,
      "step": 760
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0002698269486762313,
      "loss": 1.6425,
      "step": 780
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0002689395059902381,
      "loss": 1.6089,
      "step": 800
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00026805206330424494,
      "loss": 1.6323,
      "step": 820
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0002671646206182517,
      "loss": 1.6295,
      "step": 840
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00026627717793225854,
      "loss": 1.628,
      "step": 860
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.00026538973524626534,
      "loss": 1.6077,
      "step": 880
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.00026450229256027213,
      "loss": 1.6425,
      "step": 900
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00026361484987427893,
      "loss": 1.6204,
      "step": 920
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.00026272740718828573,
      "loss": 1.6109,
      "step": 940
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0002618399645022925,
      "loss": 1.6301,
      "step": 960
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0002609525218162993,
      "loss": 1.5943,
      "step": 980
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0002600650791303062,
      "loss": 1.6197,
      "step": 1000
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0002591776364443129,
      "loss": 1.6373,
      "step": 1020
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.00025829019375831977,
      "loss": 1.6477,
      "step": 1040
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00025740275107232657,
      "loss": 1.6209,
      "step": 1060
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.00025651530838633336,
      "loss": 1.6353,
      "step": 1080
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.00025562786570034016,
      "loss": 1.5636,
      "step": 1100
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.00025474042301434696,
      "loss": 1.6059,
      "step": 1120
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.00025385298032835375,
      "loss": 1.6347,
      "step": 1140
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00025296553764236055,
      "loss": 1.6274,
      "step": 1160
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0002520780949563674,
      "loss": 1.6472,
      "step": 1180
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.00025119065227037415,
      "loss": 1.6063,
      "step": 1200
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.000250303209584381,
      "loss": 1.6099,
      "step": 1220
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0002494157668983878,
      "loss": 1.6104,
      "step": 1240
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0002485283242123946,
      "loss": 1.6,
      "step": 1260
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0002476408815264014,
      "loss": 1.5891,
      "step": 1280
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0002467534388404082,
      "loss": 1.6042,
      "step": 1300
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.000245865996154415,
      "loss": 1.6102,
      "step": 1320
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00024497855346842183,
      "loss": 1.5693,
      "step": 1340
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0002440911107824286,
      "loss": 1.6,
      "step": 1360
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.00024320366809643543,
      "loss": 1.601,
      "step": 1380
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00024231622541044223,
      "loss": 1.5961,
      "step": 1400
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.00024142878272444902,
      "loss": 1.6018,
      "step": 1420
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00024054134003845582,
      "loss": 1.607,
      "step": 1440
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.00023965389735246262,
      "loss": 1.577,
      "step": 1460
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00023876645466646944,
      "loss": 1.6104,
      "step": 1480
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00023787901198047624,
      "loss": 1.5962,
      "step": 1500
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00023699156929448306,
      "loss": 1.6666,
      "step": 1520
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00023610412660848983,
      "loss": 1.5863,
      "step": 1540
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.00023521668392249666,
      "loss": 1.5585,
      "step": 1560
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00023432924123650346,
      "loss": 1.5449,
      "step": 1580
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.00023344179855051028,
      "loss": 1.5991,
      "step": 1600
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00023255435586451705,
      "loss": 1.5861,
      "step": 1620
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.00023166691317852387,
      "loss": 1.5734,
      "step": 1640
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00023077947049253067,
      "loss": 1.5954,
      "step": 1660
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00022989202780653747,
      "loss": 1.5945,
      "step": 1680
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0002290045851205443,
      "loss": 1.5584,
      "step": 1700
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00022811714243455106,
      "loss": 1.5883,
      "step": 1720
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0002272296997485579,
      "loss": 1.603,
      "step": 1740
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.00022634225706256468,
      "loss": 1.5563,
      "step": 1760
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0002254548143765715,
      "loss": 1.5985,
      "step": 1780
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00022456737169057828,
      "loss": 1.5644,
      "step": 1800
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0002236799290045851,
      "loss": 1.5529,
      "step": 1820
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0002227924863185919,
      "loss": 1.5739,
      "step": 1840
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.00022190504363259872,
      "loss": 1.5957,
      "step": 1860
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.00022101760094660552,
      "loss": 1.5953,
      "step": 1880
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.00022013015826061232,
      "loss": 1.5408,
      "step": 1900
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00021924271557461912,
      "loss": 1.608,
      "step": 1920
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.00021835527288862591,
      "loss": 1.5958,
      "step": 1940
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.00021746783020263274,
      "loss": 1.5593,
      "step": 1960
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0002165803875166395,
      "loss": 1.5819,
      "step": 1980
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00021569294483064633,
      "loss": 1.5724,
      "step": 2000
    },
    {
      "epoch": 0.87,
      "eval_loss": 1.7169842720031738,
      "eval_runtime": 80.638,
      "eval_samples_per_second": 24.802,
      "eval_steps_per_second": 0.781,
      "step": 2000
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.00021484987427895278,
      "loss": 1.5883,
      "step": 2020
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0002139624315929596,
      "loss": 1.5723,
      "step": 2040
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0002130749889069664,
      "loss": 1.5586,
      "step": 2060
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00021218754622097323,
      "loss": 1.5895,
      "step": 2080
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.00021130010353498003,
      "loss": 1.5882,
      "step": 2100
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0002104126608489868,
      "loss": 1.5901,
      "step": 2120
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00020952521816299362,
      "loss": 1.566,
      "step": 2140
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.00020863777547700042,
      "loss": 1.5996,
      "step": 2160
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00020775033279100724,
      "loss": 1.5622,
      "step": 2180
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.000206862890105014,
      "loss": 1.6013,
      "step": 2200
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.00020597544741902084,
      "loss": 1.5889,
      "step": 2220
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.00020508800473302764,
      "loss": 1.5414,
      "step": 2240
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00020420056204703446,
      "loss": 1.5779,
      "step": 2260
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.00020331311936104126,
      "loss": 1.5595,
      "step": 2280
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00020242567667504805,
      "loss": 1.5814,
      "step": 2300
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.00020153823398905485,
      "loss": 1.5868,
      "step": 2320
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.00020065079130306168,
      "loss": 1.5604,
      "step": 2340
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00019976334861706847,
      "loss": 1.5298,
      "step": 2360
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.00019887590593107524,
      "loss": 1.5404,
      "step": 2380
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.00019798846324508207,
      "loss": 1.5755,
      "step": 2400
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.00019710102055908886,
      "loss": 1.5494,
      "step": 2420
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0001962135778730957,
      "loss": 1.5029,
      "step": 2440
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00019532613518710249,
      "loss": 1.6112,
      "step": 2460
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00019443869250110928,
      "loss": 1.5327,
      "step": 2480
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.00019355124981511608,
      "loss": 1.6,
      "step": 2500
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0001926638071291229,
      "loss": 1.5601,
      "step": 2520
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0001917763644431297,
      "loss": 1.5523,
      "step": 2540
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00019088892175713653,
      "loss": 1.5478,
      "step": 2560
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0001900014790711433,
      "loss": 1.5298,
      "step": 2580
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00018911403638515012,
      "loss": 1.5689,
      "step": 2600
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00018822659369915692,
      "loss": 1.5527,
      "step": 2620
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00018733915101316371,
      "loss": 1.5838,
      "step": 2640
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0001864517083271705,
      "loss": 1.5526,
      "step": 2660
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0001855642656411773,
      "loss": 1.5374,
      "step": 2680
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.00018467682295518413,
      "loss": 1.5999,
      "step": 2700
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00018378938026919093,
      "loss": 1.5222,
      "step": 2720
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.00018290193758319776,
      "loss": 1.5418,
      "step": 2740
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.00018201449489720453,
      "loss": 1.5679,
      "step": 2760
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00018112705221121135,
      "loss": 1.5433,
      "step": 2780
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00018023960952521815,
      "loss": 1.5069,
      "step": 2800
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00017935216683922497,
      "loss": 1.5281,
      "step": 2820
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00017846472415323174,
      "loss": 1.5382,
      "step": 2840
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.00017757728146723857,
      "loss": 1.5693,
      "step": 2860
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00017668983878124536,
      "loss": 1.5129,
      "step": 2880
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00017580239609525216,
      "loss": 1.5448,
      "step": 2900
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.00017491495340925898,
      "loss": 1.5695,
      "step": 2920
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00017402751072326575,
      "loss": 1.5304,
      "step": 2940
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.00017314006803727258,
      "loss": 1.5516,
      "step": 2960
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00017225262535127938,
      "loss": 1.5295,
      "step": 2980
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0001713651826652862,
      "loss": 1.5575,
      "step": 3000
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.00017047773997929297,
      "loss": 1.5276,
      "step": 3020
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0001695902972932998,
      "loss": 1.546,
      "step": 3040
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0001687028546073066,
      "loss": 1.5514,
      "step": 3060
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00016781541192131342,
      "loss": 1.5015,
      "step": 3080
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0001669279692353202,
      "loss": 1.5144,
      "step": 3100
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.00016604052654932704,
      "loss": 1.5461,
      "step": 3120
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0001651530838633338,
      "loss": 1.5329,
      "step": 3140
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0001642656411773406,
      "loss": 1.5444,
      "step": 3160
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00016337819849134743,
      "loss": 1.5573,
      "step": 3180
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0001624907558053542,
      "loss": 1.5413,
      "step": 3200
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.00016160331311936102,
      "loss": 1.5227,
      "step": 3220
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.00016071587043336782,
      "loss": 1.5649,
      "step": 3240
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00015982842774737465,
      "loss": 1.5232,
      "step": 3260
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00015894098506138144,
      "loss": 1.5478,
      "step": 3280
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00015805354237538827,
      "loss": 1.5069,
      "step": 3300
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00015716609968939504,
      "loss": 1.5363,
      "step": 3320
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.00015627865700340186,
      "loss": 1.5432,
      "step": 3340
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00015539121431740866,
      "loss": 1.552,
      "step": 3360
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00015450377163141548,
      "loss": 1.5352,
      "step": 3380
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.00015361632894542225,
      "loss": 1.5385,
      "step": 3400
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00015272888625942905,
      "loss": 1.5551,
      "step": 3420
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00015184144357343587,
      "loss": 1.5241,
      "step": 3440
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.00015095400088744267,
      "loss": 1.4939,
      "step": 3460
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0001500665582014495,
      "loss": 1.5509,
      "step": 3480
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0001491791155154563,
      "loss": 1.5272,
      "step": 3500
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00014829167282946306,
      "loss": 1.593,
      "step": 3520
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0001474042301434699,
      "loss": 1.5125,
      "step": 3540
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00014651678745747668,
      "loss": 1.5342,
      "step": 3560
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.00014562934477148348,
      "loss": 1.57,
      "step": 3580
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0001447419020854903,
      "loss": 1.514,
      "step": 3600
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0001438544593994971,
      "loss": 1.4961,
      "step": 3620
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0001429670167135039,
      "loss": 1.5197,
      "step": 3640
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00014207957402751073,
      "loss": 1.5218,
      "step": 3660
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00014119213134151752,
      "loss": 1.5384,
      "step": 3680
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.00014030468865552432,
      "loss": 1.5125,
      "step": 3700
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.00013941724596953112,
      "loss": 1.5281,
      "step": 3720
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00013852980328353794,
      "loss": 1.542,
      "step": 3740
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.00013764236059754474,
      "loss": 1.5925,
      "step": 3760
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.00013675491791155154,
      "loss": 1.5318,
      "step": 3780
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.00013586747522555833,
      "loss": 1.5178,
      "step": 3800
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.00013498003253956513,
      "loss": 1.4927,
      "step": 3820
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.00013409258985357195,
      "loss": 1.5208,
      "step": 3840
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00013320514716757875,
      "loss": 1.5419,
      "step": 3860
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.00013231770448158555,
      "loss": 1.5592,
      "step": 3880
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00013143026179559235,
      "loss": 1.5229,
      "step": 3900
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.00013054281910959917,
      "loss": 1.5021,
      "step": 3920
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.00012965537642360597,
      "loss": 1.5236,
      "step": 3940
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.00012876793373761276,
      "loss": 1.5466,
      "step": 3960
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0001278804910516196,
      "loss": 1.5497,
      "step": 3980
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00012699304836562639,
      "loss": 1.5267,
      "step": 4000
    },
    {
      "epoch": 1.75,
      "eval_loss": 1.6918600797653198,
      "eval_runtime": 80.6917,
      "eval_samples_per_second": 24.786,
      "eval_steps_per_second": 0.781,
      "step": 4000
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.00012610560567963318,
      "loss": 1.5407,
      "step": 4020
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.00012521816299363998,
      "loss": 1.5482,
      "step": 4040
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00012433072030764678,
      "loss": 1.5157,
      "step": 4060
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00012344327762165358,
      "loss": 1.5324,
      "step": 4080
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0001225558349356604,
      "loss": 1.5263,
      "step": 4100
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0001216683922496672,
      "loss": 1.479,
      "step": 4120
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.00012078094956367401,
      "loss": 1.5562,
      "step": 4140
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0001198935068776808,
      "loss": 1.5621,
      "step": 4160
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.00011900606419168762,
      "loss": 1.5183,
      "step": 4180
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.00011811862150569441,
      "loss": 1.534,
      "step": 4200
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00011723117881970122,
      "loss": 1.5202,
      "step": 4220
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.00011634373613370802,
      "loss": 1.5202,
      "step": 4240
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.00011545629344771483,
      "loss": 1.5411,
      "step": 4260
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00011456885076172164,
      "loss": 1.4998,
      "step": 4280
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.00011368140807572843,
      "loss": 1.5375,
      "step": 4300
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.00011279396538973524,
      "loss": 1.5301,
      "step": 4320
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00011190652270374203,
      "loss": 1.5249,
      "step": 4340
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.00011101908001774884,
      "loss": 1.521,
      "step": 4360
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00011013163733175564,
      "loss": 1.5125,
      "step": 4380
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.00010924419464576245,
      "loss": 1.5191,
      "step": 4400
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.00010835675195976925,
      "loss": 1.5142,
      "step": 4420
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.00010746930927377606,
      "loss": 1.5164,
      "step": 4440
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.00010658186658778287,
      "loss": 1.521,
      "step": 4460
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.00010569442390178967,
      "loss": 1.5611,
      "step": 4480
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.00010485135335009612,
      "loss": 1.5303,
      "step": 4500
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00010396391066410293,
      "loss": 1.4739,
      "step": 4520
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00010307646797810973,
      "loss": 1.5753,
      "step": 4540
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.00010218902529211654,
      "loss": 1.5421,
      "step": 4560
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00010130158260612335,
      "loss": 1.5126,
      "step": 4580
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.00010041413992013015,
      "loss": 1.4661,
      "step": 4600
    },
    {
      "epoch": 2.02,
      "learning_rate": 9.952669723413696e-05,
      "loss": 1.4978,
      "step": 4620
    },
    {
      "epoch": 2.03,
      "learning_rate": 9.863925454814376e-05,
      "loss": 1.5449,
      "step": 4640
    },
    {
      "epoch": 2.04,
      "learning_rate": 9.775181186215057e-05,
      "loss": 1.5202,
      "step": 4660
    },
    {
      "epoch": 2.05,
      "learning_rate": 9.686436917615736e-05,
      "loss": 1.5084,
      "step": 4680
    },
    {
      "epoch": 2.06,
      "learning_rate": 9.597692649016417e-05,
      "loss": 1.5252,
      "step": 4700
    },
    {
      "epoch": 2.06,
      "learning_rate": 9.508948380417098e-05,
      "loss": 1.4964,
      "step": 4720
    },
    {
      "epoch": 2.07,
      "learning_rate": 9.420204111817777e-05,
      "loss": 1.504,
      "step": 4740
    },
    {
      "epoch": 2.08,
      "learning_rate": 9.331459843218458e-05,
      "loss": 1.4783,
      "step": 4760
    },
    {
      "epoch": 2.09,
      "learning_rate": 9.242715574619138e-05,
      "loss": 1.5212,
      "step": 4780
    },
    {
      "epoch": 2.1,
      "learning_rate": 9.153971306019819e-05,
      "loss": 1.4724,
      "step": 4800
    },
    {
      "epoch": 2.11,
      "learning_rate": 9.065227037420498e-05,
      "loss": 1.5012,
      "step": 4820
    },
    {
      "epoch": 2.12,
      "learning_rate": 8.97648276882118e-05,
      "loss": 1.531,
      "step": 4840
    },
    {
      "epoch": 2.13,
      "learning_rate": 8.887738500221859e-05,
      "loss": 1.5542,
      "step": 4860
    },
    {
      "epoch": 2.13,
      "learning_rate": 8.79899423162254e-05,
      "loss": 1.5318,
      "step": 4880
    },
    {
      "epoch": 2.14,
      "learning_rate": 8.710249963023221e-05,
      "loss": 1.5252,
      "step": 4900
    },
    {
      "epoch": 2.15,
      "learning_rate": 8.621505694423901e-05,
      "loss": 1.5106,
      "step": 4920
    },
    {
      "epoch": 2.16,
      "learning_rate": 8.532761425824582e-05,
      "loss": 1.476,
      "step": 4940
    },
    {
      "epoch": 2.17,
      "learning_rate": 8.444017157225262e-05,
      "loss": 1.4919,
      "step": 4960
    },
    {
      "epoch": 2.18,
      "learning_rate": 8.355272888625943e-05,
      "loss": 1.5081,
      "step": 4980
    },
    {
      "epoch": 2.19,
      "learning_rate": 8.266528620026621e-05,
      "loss": 1.5207,
      "step": 5000
    },
    {
      "epoch": 2.19,
      "learning_rate": 8.177784351427302e-05,
      "loss": 1.4792,
      "step": 5020
    },
    {
      "epoch": 2.2,
      "learning_rate": 8.089040082827982e-05,
      "loss": 1.4913,
      "step": 5040
    },
    {
      "epoch": 2.21,
      "learning_rate": 8.000295814228663e-05,
      "loss": 1.5312,
      "step": 5060
    },
    {
      "epoch": 2.22,
      "learning_rate": 7.911551545629344e-05,
      "loss": 1.492,
      "step": 5080
    },
    {
      "epoch": 2.23,
      "learning_rate": 7.822807277030024e-05,
      "loss": 1.4774,
      "step": 5100
    },
    {
      "epoch": 2.24,
      "learning_rate": 7.734063008430705e-05,
      "loss": 1.4813,
      "step": 5120
    },
    {
      "epoch": 2.25,
      "learning_rate": 7.645318739831385e-05,
      "loss": 1.4656,
      "step": 5140
    },
    {
      "epoch": 2.26,
      "learning_rate": 7.556574471232066e-05,
      "loss": 1.504,
      "step": 5160
    },
    {
      "epoch": 2.26,
      "learning_rate": 7.467830202632747e-05,
      "loss": 1.5114,
      "step": 5180
    },
    {
      "epoch": 2.27,
      "learning_rate": 7.379085934033427e-05,
      "loss": 1.5194,
      "step": 5200
    },
    {
      "epoch": 2.28,
      "learning_rate": 7.290341665434106e-05,
      "loss": 1.5165,
      "step": 5220
    },
    {
      "epoch": 2.29,
      "learning_rate": 7.201597396834787e-05,
      "loss": 1.5187,
      "step": 5240
    },
    {
      "epoch": 2.3,
      "learning_rate": 7.112853128235467e-05,
      "loss": 1.5121,
      "step": 5260
    },
    {
      "epoch": 2.31,
      "learning_rate": 7.024108859636148e-05,
      "loss": 1.4586,
      "step": 5280
    },
    {
      "epoch": 2.32,
      "learning_rate": 6.935364591036828e-05,
      "loss": 1.5132,
      "step": 5300
    },
    {
      "epoch": 2.33,
      "learning_rate": 6.846620322437508e-05,
      "loss": 1.5246,
      "step": 5320
    },
    {
      "epoch": 2.33,
      "learning_rate": 6.757876053838189e-05,
      "loss": 1.4769,
      "step": 5340
    },
    {
      "epoch": 2.34,
      "learning_rate": 6.66913178523887e-05,
      "loss": 1.4627,
      "step": 5360
    },
    {
      "epoch": 2.35,
      "learning_rate": 6.58038751663955e-05,
      "loss": 1.4826,
      "step": 5380
    },
    {
      "epoch": 2.36,
      "learning_rate": 6.49164324804023e-05,
      "loss": 1.5022,
      "step": 5400
    },
    {
      "epoch": 2.37,
      "learning_rate": 6.40289897944091e-05,
      "loss": 1.5205,
      "step": 5420
    },
    {
      "epoch": 2.38,
      "learning_rate": 6.314154710841591e-05,
      "loss": 1.5004,
      "step": 5440
    },
    {
      "epoch": 2.39,
      "learning_rate": 6.225410442242271e-05,
      "loss": 1.5024,
      "step": 5460
    },
    {
      "epoch": 2.4,
      "learning_rate": 6.136666173642951e-05,
      "loss": 1.4973,
      "step": 5480
    },
    {
      "epoch": 2.4,
      "learning_rate": 6.047921905043632e-05,
      "loss": 1.4774,
      "step": 5500
    },
    {
      "epoch": 2.41,
      "learning_rate": 5.9591776364443124e-05,
      "loss": 1.5257,
      "step": 5520
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.870433367844993e-05,
      "loss": 1.5099,
      "step": 5540
    },
    {
      "epoch": 2.43,
      "learning_rate": 5.781689099245674e-05,
      "loss": 1.5212,
      "step": 5560
    },
    {
      "epoch": 2.44,
      "learning_rate": 5.692944830646353e-05,
      "loss": 1.4723,
      "step": 5580
    },
    {
      "epoch": 2.45,
      "learning_rate": 5.604200562047034e-05,
      "loss": 1.5565,
      "step": 5600
    },
    {
      "epoch": 2.46,
      "learning_rate": 5.5154562934477144e-05,
      "loss": 1.4768,
      "step": 5620
    },
    {
      "epoch": 2.47,
      "learning_rate": 5.426712024848395e-05,
      "loss": 1.4734,
      "step": 5640
    },
    {
      "epoch": 2.47,
      "learning_rate": 5.337967756249075e-05,
      "loss": 1.4905,
      "step": 5660
    },
    {
      "epoch": 2.48,
      "learning_rate": 5.2492234876497556e-05,
      "loss": 1.4954,
      "step": 5680
    },
    {
      "epoch": 2.49,
      "learning_rate": 5.160479219050436e-05,
      "loss": 1.5024,
      "step": 5700
    },
    {
      "epoch": 2.5,
      "learning_rate": 5.071734950451116e-05,
      "loss": 1.5102,
      "step": 5720
    },
    {
      "epoch": 2.51,
      "learning_rate": 4.982990681851797e-05,
      "loss": 1.506,
      "step": 5740
    },
    {
      "epoch": 2.52,
      "learning_rate": 4.894246413252477e-05,
      "loss": 1.4996,
      "step": 5760
    },
    {
      "epoch": 2.53,
      "learning_rate": 4.8055021446531576e-05,
      "loss": 1.5254,
      "step": 5780
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.716757876053838e-05,
      "loss": 1.5021,
      "step": 5800
    },
    {
      "epoch": 2.54,
      "learning_rate": 4.6280136074545184e-05,
      "loss": 1.4792,
      "step": 5820
    },
    {
      "epoch": 2.55,
      "learning_rate": 4.539269338855198e-05,
      "loss": 1.5058,
      "step": 5840
    },
    {
      "epoch": 2.56,
      "learning_rate": 4.4505250702558785e-05,
      "loss": 1.5146,
      "step": 5860
    },
    {
      "epoch": 2.57,
      "learning_rate": 4.361780801656559e-05,
      "loss": 1.5408,
      "step": 5880
    },
    {
      "epoch": 2.58,
      "learning_rate": 4.27303653305724e-05,
      "loss": 1.5136,
      "step": 5900
    },
    {
      "epoch": 2.59,
      "learning_rate": 4.1842922644579204e-05,
      "loss": 1.5243,
      "step": 5920
    },
    {
      "epoch": 2.6,
      "learning_rate": 4.095547995858601e-05,
      "loss": 1.4772,
      "step": 5940
    },
    {
      "epoch": 2.61,
      "learning_rate": 4.006803727259281e-05,
      "loss": 1.4853,
      "step": 5960
    },
    {
      "epoch": 2.61,
      "learning_rate": 3.918059458659961e-05,
      "loss": 1.4746,
      "step": 5980
    },
    {
      "epoch": 2.62,
      "learning_rate": 3.829315190060641e-05,
      "loss": 1.4781,
      "step": 6000
    },
    {
      "epoch": 2.62,
      "eval_loss": 1.6820251941680908,
      "eval_runtime": 80.6511,
      "eval_samples_per_second": 24.798,
      "eval_steps_per_second": 0.781,
      "step": 6000
    }
  ],
  "max_steps": 6861,
  "num_train_epochs": 3,
  "total_flos": 2.87927364490992e+18,
  "trial_name": null,
  "trial_params": null
}
